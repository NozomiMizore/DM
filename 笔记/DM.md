# 第一章 导论
## 1.1 需求
### 建设数字经济面临的问题：   
- 自动数据收集工具和成熟的数据库系统应用导致大量数据积累到数据库中亟待分析
- 数据量大单知识贫乏——仅有0.5%的数据能用来分析    
  
### 解决办法：数据仓库和数据挖掘   
- 数据仓库与联机分析(OLAP)
- 挖掘感兴趣的模式   

## 1.2 数据挖掘的定义及应用
### 定义：
数据挖掘是一个跨学科的计算机科学分支。它是用人工智能、机器学习、统计学和数据库的交叉方法在相对较大型的数据集中发现模式的计算过程。

### 其他名称：
-  KDD （Knowledge discovery in databases)
-  知识提取（knowledge extraction）, data/pattern analysis, data archaeology, data dredging, information harvesting, business intelligence, etc.

### 应用：
- 数据分析和决策支持（Data analysis and decision support)
    - 市场分析和管理（Market analysis and management)
    - 风险分析和管理（Risk analysis and management）
    - 欺诈和非凡模式（孤立点）检测
- 文本挖掘 (news group, email, documents) and Web mining
- 流数据挖掘（Stream data mining）
- DNA 和生物挖掘（DNA and bio-data analysis）
## 1.3 数据挖掘的步骤
### 知识挖掘的核心：数据挖掘

### 知识挖掘步骤：
![图片](assets/1.png)

### 数据挖掘和商业智能：
![图片](assets/2.png)

### 典型数据挖掘系统的步骤和架构：
![图片](assets/3.png)

### KDD（知识挖掘）的步骤：
- 学习应用领域相关知识和应用目标
- 创建目标数据集（选择数据）
- 数据清洗和预处理（可能花费60%的时间）
- 数据压缩和转换(发现有用的特征，进行维度和变量压缩，不变表示法)
- 选择数据挖掘的功能（摘要，分类，回归，关联，聚类）
- 选择数据挖掘算法
- 进行数据挖掘（寻找感兴趣的模式）
- 模式评估和知识表示（可视化，转化，去除冗余的模式）
- 使用挖掘出的知识

## 1.4 数据挖掘的特点
### 分类应用场景
一般功能
- 描述性数据挖掘
- 预测性数据挖掘

不同的特点，不同的分类
- 被挖掘数据的种类
  - 关系型数据
  - 数据仓库
  - 事务型数据库
  - 流数据
  - 面向对象的数据
  - 活跃的数据
  - 空间数据
  - 时间序列数据
  - 文本数据
  - 多媒体数据
- 被发现知识的种类
  - 特征
  - 描述
  - 关联
  - 分类
  - 聚类
  - 趋势
  - 离群值分析
- 使用的技术的种类
  - 面向数据库技术
  - 数据仓库
  - 机器学习
  - 统计学
  - 可视化
- 适用应用的种类
  - 零售业
  - 通讯业
  - 银行
  - 欺诈分析
  - 生物数据挖掘
  - 股市分析
  - web挖掘
- 数据源
  - 关系型数据库
  - 数据仓库
  - 事务型数据库
  - 高级数据库和信息存储库
  - 面向对象数据库
  - 时间和空间数据
  - 时间序列数据
  - 流数据
  - 多媒体数据库
  - 异构和遗产数据库
  - 文本数据库

功能：
- 概念描述：特征化和区分
- 关联：相关性和因果性
- 分类和预测
  - 为了将来的预测创建用来描述概念和区别类别的模型
  - 表示：决策树，分类规则，神经网络
  - 预测一些未知值或者确实值
- 聚类分析
  - 标签未知
  - 离群值分析
    - 离群值是与数据常规表现相异的值
    - 离群值不是噪声也不是异常，它对欺诈识别和罕见事件分析非常有用
- 趋势和演变分析
  - 趋势和偏离
  - 序列模式挖掘
  - 相似性
- 其他模式导向或统计分析

兴趣度度量
- 并不是所有挖掘出的模式都是感兴趣的
- 兴趣度度量的因素（易于理解，对新数据或测试数据有一定置信度，潜在有用，被用户所需求）
- 客观或主观兴趣度度量
  - 客观兴趣度度量：基于统计和模式结构
  - 主观兴趣度度量：基于用户对数据的信任，未预料性，新颖性，可操作性
- 尽可能的发现所有感兴趣的模式
- 只寻找感感兴趣的模式：最优化问题
  - 首先概括所有模式，然后过滤掉不感兴趣的模式
  - 只生成感兴趣的模式-挖掘查询优化

使用的技术
![图片](assets/4.png)

## 1.5 数据挖掘VS其他相关技术
人工智能、模式识别、信息检索、深度学习、统计、数据库都与数据挖掘相关

数据挖掘和机器学习的对比
![图片](assets/5.png)

__领域专家或领域知识对于DM是重要的__
- 验证数据的合理性
- 验证信息的有效性

- 线上分析型数据挖掘集成了数据挖掘和OLAP技术
- 交互式挖掘多层次知识(通过钻取，上卷，切片，切块，旋转对数据进行不同级别的抽象并进行挖掘)
- 集成多种挖掘功能（比如特征化分类，先聚类再关联）

## 1.6 数据挖掘的焦点和挑战
- 挖掘方法
  - 从多类数据中挖掘不同的知识
  - 性能：效率和拓展性
  - 模式评估：问题感兴趣度
  - 背景知识
  - 处理噪声和不完整数据，包括不完整的标签
  - 并行、分布式、增量化的挖掘方法
  - 将当前存在的知识和已发现的知识集成起来：知识融合
- 用户交互
  - 数据挖掘查询语言
  - 结果的可视化和表示
  - 对多层次抽象出（不同粒度）的知识进行集成挖掘
- 应用和社会影响
  - 特点领域数据挖掘和不可见数据挖掘
  - 保护数据安全性，完整性和隐私
  
## 1.7 数据挖掘和伦理
- 数据源是否合法
- 如何使用挖掘结果
  - 贷款审批中区别对待（种族，宗教，性别）
  - 超市销售中货架摆放影响购物时间
- 隐私保护
  - 数据脱敏
  - 匿名信件
  - 人肉

## 1.8 总结
- 数据挖掘：从大量数据中发现感兴趣的模式
- 在巨大需求和广泛应用下的数据库技术的自然进化
- KDD过程包括数据清洗，数据集成，数据选择，数据转换，数据挖掘，模式评估，知识表示
- 数据挖掘可以在各种信息库中进行
- 数据挖掘的功能：特征化，数据区分，关联，分类，聚类，离群点检测和趋势分析
- 数据挖掘系统和架构
- 数据挖掘中的主要问题

<div STYLE="page-break-after: always;"></div>

# 第二章 数据仓库

## 2.1 数据及数据类型
__吕俊伟这节ppt是空的 望周知__

## 2.2 数据库与数据仓库
### 数据仓库与数据库的简单对比
__数据库为操作而生，数据仓库为分析而生__

事务操作数据库：
- 设计原则：
  - 范式（规范并减少冗余）
  - 三少（表个数，组合主键的字段个数，表中的字段个数）
- 目的：
  - 快速的操作
  - 较少的冗余
- 在数据冗余和处理速度之间找到合适的平衡点

面向数据分析时，数据仓库在数据库的基础上，更注重：
- 从存储的设计上考虑数据分析的需求，不再简单的追求范式约束
- 异构环境的转换和共享：数据分析不可避免的需要大量的历史数据，异构数据，__如何设计和实现数据的转换和共享是数据仓库的一个重要问题__
- 为分析和决策提供支持：需要对大量历史数据能方便的进行宏观的或微观的汇总和表示，实现数据不同粒度、角度的表示

### 数据仓库的定义
- W.H.Inmon的定义：“数据仓库是支持管理决策过程的、面向主题的、集成的、随时间而变的、持久的数据集合”
- 另外一个定义：“数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。”

### 数据仓库的特点
1.面向主题
  - 面向主题是数据仓库显著区别于关系数据库系统的一个特征（操作型数据库面向事务处理transaction）
  - Subject（主题）是指用户使用数据仓库进行决策时所关心的重点方面，一个主题通常与多个操作型信息系统相关。
    - 围绕一些主题，如顾客、供应商、产品等
    - __关注决策者的数据建模与分析，而不是集中于日常操作和事务处理__。
    - 排除对于决策无用的数据，提供特定主题的简明视图。
    - 操作性环境和分析性环境![图片](assets/6.png)
2.集成：一个数据仓库是通过集成多个异种数据源来构造的。
  - 比如关系数据库，一般文件，联机事务处理记录
  - 数据仓库的数据有来自于分散的操作型数据，将所需数据从原来的数据中抽取出数据仓库的核心进行加工与集成，统一综合后进入数据仓库; 
  - 这个过程中需要使用**数据清理和数据集成**技术
    - 确保命名约定、编码结构、属性度量等的一致性
    - 当数据被移到数据仓库时，它们要经过转化，如字段名统一，单位统一等。
    - 还有一定的汇总，统计等功能
3.随时间变化
  - 从存储角度，数据仓库的数据变化多是一次性大量存储或移除，**DW数据内容不可修改（修改应保留修改痕迹）**。
  - 从分析角度，DW的数据以只读格式保存，其随时间变化相对稳定。
  - 数据仓库是从历史的角度提供信息
    - 数据仓库的时间范围比操作数据库系统要长的多
      - 操作数据库系统: 主要保存当前数据。
      - 数据仓库:从历史的角度提供信息（比如过去 5-10 年）
    - 数据仓库中的每一个关键结构都隐式或显式地包含时间元素，而操作数据库中的关键结构可能就不包括时间元素。
4.数据不可更新、不易丢失
  - 尽管数据仓库中的数据来自于操作数据库，但他们却是在物理上分离保存的。
    - 操作数据库的更新操作不会出现在数据仓库环境下
    - 不需要事务处理，恢复，和并发控制等机制
    - 数据的初始转载和数据访问（读操作）
    - __数据仓库中的数据也需要定期进行清理__
5.汇总的
  - 操作性数据映射成决策可用的格式。 
6.大容量
  - 时间序列数据集合通常都非常大。 
7.非规范化的
  - Dw数据可以是而且经常是冗余的。 
8.元数据
  - 将描述数据的数据保存起来
9.数据源
  - 据来自内部的和外部的非集成操作系统。

__数据集市(DataMarts) ：__   
为了特定的应用目的或应用范围，而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据(subject area)。

### DW中数据汇总的示例
![图片](assets/7.png)

### DW上的OLAP操作
- 维
  - 是观察数据的特定角度，是考虑问题时的一类属性（时间维、地点维））
- 维的层次
  - 数据某个特定维度还存在细节程度不同的各个描述
- 维的成员
  - 维的一个取值
- 多维数组
  - 维和变量的组合表示
- 数据立方体是一种对多维的数据模型的描述方式
- 基本的OLAP操作
![图片](assets/9.png)
数据仓库的三种应用
- 信息处理
  - 支持查询和基本的统计分析，并使用交叉表、表、图标和图进行报表处理
- 分析处理
  - 对数据仓库中的数据进行多维数据分析
  - 支持基本的OLAP操作，切块、切片、上卷、下钻、转轴等，多粒度的知识表示
- 构建规范
  - 数据的类型
    - 数据库(mysql):在线交易数据
    - 数据仓库(hive):历史数据
  - 建模
    - 数据库(mysql):数据库的建模遵循三范式。
    - 数据仓库(hive):采用维键建模。
  - 存储
    - 数据库(mysql):存储在线交易数据。
    - 数据仓库(hive):存多种数据,数据量大,历史数据。
  - 设计
    - 数据库：尽量避免冗余符合范式规则。
    - 数据仓库：引入冗余，反范式方式设计，分析数据
  - 目的
    - 数据库：为捕获数据而设计。
    - 数据仓库：为分析数据而设计。

## 2.3 数据仓库的概念模型
### 一些概念：
- DW中数据存在多个维：如客户，地点，产品等
- 不同维之间的交叉点称为事实
- 概念模型用来构建这种数据维与事实间的关系
- 最流行的数据仓库概念模型是多维数据模型。这种模型可以以星型模式、雪花模式、事实或星座模式的形式存在。

### 各种模型
- 星座模型
  - 一种非正规化的结构，每个维度都直接与事实表连接，不存在渐变维度
  - 特点：有一定的冗余，查询效率高，维护方便
  ![图片](assets/10.png)
- 雪花模型
  - 是星型模式的变种，其中某些维表是规范化的，因而把数据进一步分解到附加表中。结果，模式图形成类似于雪花的形状。**有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上**
  - 冗余小，查询效率低，维护困难
  ![图片](assets/11.png)
  ![图片](assets/12.png)
- 事实星座模型：
  - 复杂应用可能需要多个事实表共享维表, 这种模式可以看作星型模式的汇集，因此称为星系模式（galaxy schema），或者事实星座（fact constellation） 
  - 由多个主题构成，包含多个事实表，而维表是共享，避免冗余
  - 适用于主题较多情况
  ![图片](assets/13.png)
- 设计原则
  - 数据仓库的设计遵循自顶向下的方式来构建
  - 维表之间交叉减少
  - 级联的层次减少

## 2.4 数据仓库的体系结构
### 三层数据仓库架构
![图片](assets/14.png)
- 底层：数据仓库的数据库服务器
  - 关注的问题：如何从这一层提取数据来构建数据仓库（通过Gateway（ODBC,JDBC,OLE/DB等）来提取）
- 中间层：OLAP服务器
  - 关注的问题：OLAP服务器如何实施（关系型OLAP，多维OLAP等）
- 前端客户工具层
  - 关注的问题：查询工具、报表工具、分析工具、挖掘工具等

### 数据仓库开发的困难和解决方法
- 困难
  - 自顶向下的开发方法从全系统的角度提供解决方案，使得（模块）集成的问题最小；但是该方法十分昂贵，需要对组织进行长期研究和建模分析。
  - 自底向上方法提供了更多的开发灵活性，价格便宜；但往往会遇到集成问题（每个模块单独运行都没有问题，但是一集成就出异常）
- 解决方法
  - 使用有序、反复、一次一步的递增式、演化性的开发方法
  - 高层数据模型->企业仓库和数据集市并行开发->通过分布式模型集成各数据集市->多层数据仓库

## 2.5 数据仓库到数据挖掘
__不得不吐槽吕俊伟ppt的混乱__

<div STYLE="page-break-after: always;"></div>

# 第三章 数据预处理与表示
__（数据驱动式）数据分析的基本步骤__
![图片](assets/15.png)

## 3.1 数据预处理的定义
### 一些定义
- __数据预处理是指在数据分析任务以前对数据进行的一些处理，以减小数据某些方面对算法性能的影响__
  - 榨果汁-----切块
  - 分类----去噪音、缺失值填充、归一化等
- 特征选择是从原始特征数据集中选择出子集，是一种包含的关系，**没有更改原始的特征空间**。
- 特征提取是通过属性间的关系，如组合不同的属性得到新的属性，这样就**改变了原来的特征空间**。
- 特征表示是学习更高层的、**具有语义等任务相关信息**的表示

### 数据预处理的重要性
- 没有高质量的数据，就没有高质量的挖掘结果
  - 高质量的决策必须依赖高质量的数据
    - 重复值或者空缺值将会产生不正确的或者令人误导的统计
  - 数据仓库需要对高质量的数据进行一致地集成
  - 低质量的数据 VS 算法性能
  - 低质数据挖掘是当前一个热门的研究方向
- 数据预处理将是构建数据仓库或者进行数据挖掘的工作中**占工作量最大**的一个步骤

### 数据质量问题表现形式
- 误差：测量误差和收集误差或错误     难以处理
- 数据不一致
  - 例如：在编码或者命名上存在差异
  - 例如：过去的等级： “1,2,3”,  现在的等级： “A, B, C”
  - 例如：Age=“42” Birthday=“03/07/1997”
-  噪声
  - 包含错误或者孤立点或离群点（outlier）
  - 明显噪声和非明显噪声
- 重复数据 duplication
  - 区分重复合法与否
- 数据不完整
  - 缺少数据值
  - 缺乏某些重要属性
  - 仅包含汇总数据
- 时效性
- 相关性
- 采样合理性

## 3.2 描述性数据汇总
### 动机：为了更好的理解数据
  - 获得数据的总体印像
  - 识别数据的典型特征
  - 凸显噪声或离群点
  - 检查不一致数据，异常数据

### 度量数据的中心趋势
  - 可以用均值、中位数、众数（模）、中列数等度量
  - 算术平均值
  ![图片](assets/16.png)
  - 加权算术平均
  ![图片](assets/17.png)
  - 截断均值（trimmed mean）：去掉高、低极端值得到的均值
    - 例如计算平均工资时，可以截掉上下各2％的值后计算均值，以抵消少数极端值的影响
  - 中位数：有序集的中间值或者中间两个值平均
    - 整体度量；但是可以通过插值法计算近似值
    ![图片](assets/18.png)
    ![图片](assets/19.png)
  - 众数（Mode，也叫模）：集合中出现频率最高的值
    - 单峰的（unimodal，也叫单模态）、双峰的（bimodal）、三峰的（trimodal）；多峰的（multimodal）
    - 对于适度倾斜（非对称的）的单峰频率曲线，可以使用以下经验公式计算众数
    ![图片](assets/20.png)
    - 对称与正倾斜、负倾斜数据的中位数、均值和众数
    ![图片](assets/21.png)

### 度量数据的离散程度
  - 四分位数、四分位数极差、方差等
  - 最常用度量：极差、五数概括（基于四分位数）、中间四分位数极差和标准差
    - 极差（range）：数据集的最大值和最小值之差
    - 百分位数(percentile)：第k个百分位数是具有如下性质的值x：k%的数据项位于或低于x
      - 中位数就是第50个百分位数
    - 四分位数：Q1 (25th percentile), Q3 (75th percentile)
    - 中间四分位数极差(IQR)： IQR = Q3 – Q1 
    - 孤立点：通常我们认为：挑出落在至少高于第三个四分位数或低于第一个四分位数 1.5×IQR处的值
    - 五数概括: min, Q1, Median, Q3, max
    - 盒图：数据分布的一种直观表示
    - 方差和标准差
      - 方差s2：n个观测之x1,x2...xn的方差是
      ![图片](assets/22.png)
      - 标准差s是方差s2的平方根
        - 标准差s是关于平均值的离散的度量，因此**仅当选平均值做中心度量时使用**
        - 所有观测值相同则 s＝0，否则 s>0
        - 方差和标准差都是代数度量

### 度量分类
  - 分布式度量(distributive measure)：将函数用于n个聚集值得到的结果和将函数用于所有数据得到的结果一样
    - 比如：count()，sum()，min()，max()等
  - 代数度量(algebraic)：可以通过在一个或多个分布式度量上应用一个代数函数而得到
    - 比如：平均值函数avg()  avg() =sum()/count()
  - 整体度量(holistic)：必须对整个数据集计算的度量
    - 比如：median()，mode()，rank()

### 基本统计类描述的图形显示
  - 常用的显示数据汇总和分布的方法：
    - 直方图、分位数图、q-q图、散布图和局部回归曲线
  - 直方图: 一种单变量图形表示方法
    - 将数据分布划分成不相交的子集或桶，通常每个桶宽度一致并用一个矩形表示，其高度表示桶中数据在给定数据中出现的计数或频率
  
  ![图片](assets/23.png)
  - 散布图
    - 确定两个量化的变量之间看上去是否有联系、模式或者趋势的最有效的图形方法之一
    - 散布图中的每个值都被视作代数坐标对，作为一个点画在平面上
    - 易于观察双变量数据在平面上的分布
  ![图片](assets/24.png)
  - loess曲线
    - loess曲线为散布图添加一条平滑的曲线，以便更好的观察两个变量间的依赖模式
    - Loess (local regression)意指“局部回归”，为了拟合loess曲线，需要两个参数：平滑参数α ，被回归拟合的多项式的阶λ 
  
  ![图片](assets/25.png)

### 定量数据分布分析例题
下表是描述菜品捞起生鱼片在2014年第二个季度的销售数据，绘制销售量的频率分布表、频率分布图，对该定量数据做出相应的分析。
![图片](assets/26.png)
- 第一步：求极差：
极差 = 最大值 - 最小值 = 3960-45=3915
- 第二步：分组：
这里根据业务数据的含义，可取组距为500。
组数 = 极差/组距 = 3915/500=7.83=8
- 第三步：决定分点，如下表：
![图片](assets/27.png)
- 第四步：绘制频率分布表
![图片](assets/28.png)
- 第五步：绘制频率分布直方图
若以2014年第二季度捞起生鱼片每天的销售额为横轴，以各组段的频率密度（频率与组距之比）为纵轴，表3‑3的数据可绘制成频率分布直方图，见图：
![图片](assets/29.png)

### Pyhthon统计数据
![图片](assets/30.png)
![图片](assets/31.png)

## 3.3 结构化数据
### 3.3.1 数据预处理（缺失值，噪音，重复数据，数据变换，离散化，采样Sampling， 维归约及选择）
![图片](assets/32.png)
  - 数据清理
    - 填写空缺的值，平滑噪声数据，识别、删除孤立点，解决不一致性
    - 空缺值处理
      - 引起空缺值的原因
        - 设备异常
        - 与其他已有数据不一致而被删除
        - 因为误解而没有被输入的数据
        - 在输入时，有些数据因为得不到重视而没有被输入
        - 对数据的改变没有进行日志记载
      - 空缺值处理方法
        - 忽略元组
          - 当类标号缺少时通常这么做（假定挖掘任务设计分类或描述），当每个属性缺少值的百分比变化很大时，它的效果非常差。
        - 人工填写空缺值：工作量大，可行性低
        - 填充：基于对已知的取值的观察和分析，对缺失值进行自动填充
          - 用一个全局变量填充空缺值：比如使用unknown或∞
          - 使用属性的（加权/截断）平均值/众数/中位数填充空缺值
          - 基于Bayesian，knn或判定树推断的方法
          - 插值方法：Hermite插值、分段插值、样条插值法，而最主要的有拉格朗日插值法和牛顿插值法。
            - 拉格朗日插值法
            ![图片](assets/33.png)
              - 据若干个不同的地方得到相应的观测值，拉格朗日插值法可以拟合一个多项式（拉格朗日（插值）多项式）。
              - 数学上来说，拉格朗日插值法可以给出一个恰好穿过二维平面上若干个已知点的多项式函数。
              - 该方法的使用条件：
                - 假设x，y符合多项式分布
                - 需找到一个合理的x
      - 众数或均值等填充方法有以下特点：
        - 仅针对缺失值的这一列数据进行分析
        - 分析的技术主要是简单的统计和数值分布因此，其不能完成**??**条件下的缺失值填充
    - 噪声数据
      - 噪声：一个测量变量中的随机错误或偏差
      - 引起不正确属性值的原因
        - 数据收集工具的问题
        - 数据输入错误
        - 数据传输错误
        - 技术限制
        - 命名规则的不一致
      - 其它需要数据清理的数据问题
        - 重复记录
        - 不完整的数据
        - 不一致的数据
      - 处理方法
        - 分箱(binning)
          - 首先排序数据，并将他们分到等深的箱中
          - 然后可以按箱的平均值平滑、按箱中值平滑、按箱的边界平滑等等
        ![图片](assets/34.png)
        - 回归
          - 通过让数据适应回归函数来平滑数据
        - 聚类
          - 通过聚类分析检测离群点，消除噪声
          - 聚类将类似的值聚成簇。直观的，落在簇集合之外的值被视为离群点
         ![图片](assets/35.png)
        - 计算机和人工检查结合
          - 计算机检测可疑数据，然后对它们进行人工判断
    - Python实现数据清理
      - 缺失值处理
      ![图片](assets/36.png)
      - 噪声处理
      ![图片](assets/37.png)
      - 重复值处理
        - 去掉重复数据train.drop_duplicates()
  - 数据集成
    - 集成多个数据库、数据立方体或文件
  - 数据变换
    - 规范化和聚集
    - 规范化
      - 必要性：数值差异过大会导致计算值的偏差
      - 改变了数据的值
      - 规范化方法
        - 简单的规范化：Log (x)，sin(x)，x/sum(x)
        - 最小－最大规范化
        ![图片](assets/38.png)
        - z-score规范化(最大最小值未知，或者离群点影响较大的时候适用)
        ![图片](assets/39.png)
        - 小数定标规范化

        ![图片](assets/40.png)
        ![图片](assets/41.png)
  - 数据归约
    - 得到数据集的压缩表示，它小得多，但可以得到相同或相近的结果
    - 数据归约是指在对挖掘任务和数据本身内容理解的基础上、寻找依赖于发现目标的数据的有用特征，以缩减数据规模，从而在尽可能保持数据原貌的前提下，最大限度地精简数据量。
  - 数据离散化
    - 数据归约的一部分，通过概念分层和数据的离散化来规约数据，对数字型数据特别重要

### 3.3.2 数据表示（特征提取）



